{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import load_model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('lenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returndigit(path):\n",
    "    img =cv2.imread(path,0)\n",
    "    invereted_img = 255-img\n",
    "    invereted_img = invereted_img.astype('float32')\n",
    "    invereted_img /= 255\n",
    "    imgheight, imgwidth = invereted_img.shape\n",
    "    old_i = 0\n",
    "    finalnumber = []\n",
    "    for i in range(0,imgwidth-1):\n",
    "        count = 0\n",
    "        for j in range(0,imgheight):\n",
    "            if invereted_img[j][i] == 0:\n",
    "                count +=1\n",
    "            if count == imgheight:\n",
    "                croppedimg = invereted_img[:,old_i:i+1]\n",
    "                croppedwidth = croppedimg.shape[1]\n",
    "                old_i = i\n",
    "                if croppedwidth <= 28 and croppedwidth >= 5:\n",
    "                    croppedimg = np.concatenate((croppedimg, np.zeros((28, (28-croppedwidth)),np.uint8)),axis=1)\n",
    "                    cv2.imwrite('/media/windows-share/divided/'+str(old_i)+'.png',croppedimg)\n",
    "                    croppedimg = croppedimg.reshape(1,*croppedimg.shape,1)\n",
    "                    pred = model.predict(croppedimg).tolist()[0]\n",
    "                    finalnumber.append(pred.index(max(pred)))\n",
    "    return finalnumber\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '/media/windows-share/Combined/number_4.png'\n",
    "path = '/media/windows-share/5.png'\n",
    "Number =returndigit(path)\n",
    "Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6fbbc18a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noAg/ENT/A6B9MpGdgF3IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6fbbae47f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(255-cv2.imread(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgp =cv2.imread('/media/windows-share/114.png')\n",
    "imgp = cv2.cvtColor(imgp, cv2.COLOR_BGR2GRAY)\n",
    "imgp = imgp.reshape(1,*imgp.shape,1)\n",
    "impg = imgp/255\n",
    "imgp.shape\n",
    "model.predict(imgp).tolist()[0].index(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# ret, thresh = cv2.threshold(invereted_img,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',x_train[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
